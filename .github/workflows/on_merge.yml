name: Deploy Lambda to prod, logs to CloudWatch.

on:
  push:
    branches:
      - main

permissions:
  id-token: write
  contents: read

jobs:
  deploy-prod:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{secrets.AWS_ACCESS_KEY_ID}}
      AWS_SECRET_ACCESS_KEY: ${{secrets.AWS_SECRET_ACCESS_KEY}}
      AWS_REGION: ${{secrets.AWS_REGION}}
      LAMBDA_NAME_PROD: ${{secrets.LAMBDA_NAME_PROD}}
      S3_BUCKET_PROD: ${{secrets.S3_BUCKET_PROD}}
      S3_PATH_PROD: ${{secrets.S3_PATH_PROD}}
      CF_STACK_NAME_PROD: ${{secrets.CF_STACK_NAME_PROD}}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check required files
        run: |
          python tests/check_required_files.py

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Zip Lambda Function
        run: zip ${{ secrets.LAMBDA_NAME_PROD }}.zip lambda_function_advance.py

      - name: Upload to S3 (Prod)
        run: aws s3 cp ${{ secrets.LAMBDA_NAME_PROD }}.zip s3://${{ secrets.S3_BUCKET_PROD }}/${{ secrets.S3_PATH_PROD }}

      - name: Deploy CloudFormation (Prod)
        run: |
          aws cloudformation deploy \
            --stack-name ${{ secrets.CF_STACK_NAME_PROD }} \
            --template-file infrastructure/cloudformation/ec2-shutdown-advance.yml \
            --capabilities CAPABILITY_NAMED_IAM \
            --parameter-overrides \
              LambdaFunctionName=${{ secrets.LAMBDA_NAME_PROD }} \
              LambdaCodeBucket=${{ secrets.S3_BUCKET_PROD }} \
              LambdaCodeKey=${{ secrets.S3_PATH_PROD }}


      - name: Create log stream and put log event
        run: |
          LOG_STREAM_NAME=$(date -u +"%Y-%m-%dT%H-%M-%SZ")
                
          # Set log group based on branch
          if [ "${{ github.ref }}" = "refs/heads/main" ]; then
            LOG_GROUP_NAME="${{ secrets.PROD_LOG_GROUP }}"
          else
            LOG_GROUP_NAME="${{ secrets.BETA_LOG_GROUP }}"
          fi
                
          # Check if log group name is set
          if [ -z "$LOG_GROUP_NAME" ]; then
            echo "Error: Log group name is empty. Please check your secrets PROD and BETA are set."
            exit 1
          fi
                
          COMMIT_SHA="${{ github.sha }}"
          GITHUB_ACTOR="${{ github.actor }}"
          WORKFLOW_NAME="${{ github.workflow }}"
          TIMESTAMP=$(date +%s%3N)
          ec2_instance_id=$(aws ec2 describe-instances --filters Name=instance-state-name,Values=running --query "Reservations[].Instances[].InstanceId" --output json)
      
                
          echo "Using log group: $LOG_GROUP_NAME"
          echo "Log stream: $LOG_STREAM_NAME"
                
          # Create log group (ignore error if it already exists)
          aws logs create-log-group \
            --log-group-name "$LOG_GROUP_NAME" || true
                
          # Create log stream (ignore error if it already exists)
          aws logs create-log-stream \
            --log-group-name "$LOG_GROUP_NAME" \
            --log-stream-name "$LOG_STREAM_NAME" || true
                
          # Create the log message as a single string
          LOG_MESSAGE="Workflow: ${WORKFLOW_NAME}, Commit: ${COMMIT_SHA}, Actor: ${GITHUB_ACTOR}, Branch: ${{ github.ref_name }}, Timestamp: ${TIMESTAMP}", ec2_instance_id=${ec2_instance_id}
                
          # Put log event with proper JSON format
          aws logs put-log-events \
            --log-group-name "$LOG_GROUP_NAME" \
            --log-stream-name "$LOG_STREAM_NAME" \
            --log-events "[{\"timestamp\":$TIMESTAMP,\"message\":\"$LOG_MESSAGE\"}]"
      
      - name: Logging Successful
        run: |
            echo "Logs are now present in CloudWatch"